{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3812fff4",
   "metadata": {},
   "source": [
    "# L2 Regularization (Ridge Regression)\n",
    "\n",
    "L2 regularization adds a penalty proportional to the **square of the weights** \n",
    "to the loss function.\n",
    "\n",
    "It is mainly used to:\n",
    "\n",
    "- Prevent overfitting\n",
    "- Reduce model variance\n",
    "- Stabilize weight estimates\n",
    "- Handle multicollinearity\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Problem Setup\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "X \\in \\mathbb{R}^{n \\times d}\n",
    "$$\n",
    "\n",
    "be the feature matrix, where:\n",
    "\n",
    "- $n$ = number of samples  \n",
    "- $d$ = number of features  \n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "y \\in \\mathbb{R}^{n}\n",
    "$$\n",
    "\n",
    "be the target vector.\n",
    "\n",
    "We want to learn:\n",
    "\n",
    "$$\n",
    "w \\in \\mathbb{R}^{d}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Linear Regression (Without Regularization)\n",
    "\n",
    "The ordinary least squares objective:\n",
    "\n",
    "$$\n",
    "J(w) = \\frac{1}{n} \\| y - Xw \\|_2^2\n",
    "$$\n",
    "\n",
    "This minimizes training error only.\n",
    "\n",
    "Problem:\n",
    "\n",
    "- Can overfit\n",
    "- Large variance\n",
    "- Unstable when features are correlated\n",
    "\n",
    "---\n",
    "\n",
    "## 3. L2 Regularized Objective (Ridge)\n",
    "\n",
    "L2 adds a squared weight penalty:\n",
    "\n",
    "$$\n",
    "J(w) = \\frac{1}{n} \\| y - Xw \\|_2^2 + \\lambda \\| w \\|_2^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. L2 Norm Definition\n",
    "\n",
    "The L2 norm is:\n",
    "\n",
    "$$\n",
    "\\| w \\|_2^2 = \\sum_{j=1}^{d} w_j^2\n",
    "$$\n",
    "\n",
    "So the objective becomes:\n",
    "\n",
    "$$\n",
    "J(w) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - x_i^T w)^2\n",
    "+ \\lambda \\sum_{j=1}^{d} w_j^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Understanding Each Term\n",
    "\n",
    "### (1) Data Fitting Term\n",
    "\n",
    "$$\n",
    "\\frac{1}{n} \\| y - Xw \\|_2^2\n",
    "$$\n",
    "\n",
    "Ensures the model fits the data.\n",
    "\n",
    "---\n",
    "\n",
    "### (2) Regularization Term\n",
    "\n",
    "$$\n",
    "\\lambda \\| w \\|_2^2\n",
    "$$\n",
    "\n",
    "Penalizes large weights.\n",
    "\n",
    "Effect:\n",
    "\n",
    "- Shrinks coefficients\n",
    "- Reduces variance\n",
    "- Improves generalization\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Closed Form Solution (Very Important)\n",
    "\n",
    "Unlike L1, L2 has a closed-form solution:\n",
    "\n",
    "$$\n",
    "w = (X^T X + \\lambda I)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $I$ = identity matrix  \n",
    "- $\\lambda I$ ensures invertibility  \n",
    "\n",
    "This makes Ridge numerically stable.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Geometric Interpretation\n",
    "\n",
    "Constraint form:\n",
    "\n",
    "$$\n",
    "\\min_w \\| y - Xw \\|_2^2\n",
    "\\quad \\text{subject to} \\quad\n",
    "\\| w \\|_2^2 \\le t\n",
    "$$\n",
    "\n",
    "The L2 constraint region forms a **circle (or sphere in higher dimensions)**.\n",
    "\n",
    "Because the boundary is smooth:\n",
    "\n",
    "- Weights shrink\n",
    "- But rarely become exactly zero\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Effect of Increasing Î»\n",
    "\n",
    "As $\\lambda$ increases:\n",
    "\n",
    "- All weights shrink smoothly\n",
    "- No exact zeros\n",
    "- Model becomes more biased\n",
    "- Variance decreases\n",
    "\n",
    "This illustrates the **biasâ€“variance tradeoff**.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. L1 vs L2 Comparison\n",
    "\n",
    "| Property | L1 | L2 |\n",
    "|-----------|------|------|\n",
    "| Penalty | $\\sum |w_j|$ | $\\sum w_j^2$ |\n",
    "| Sparsity | Yes | No |\n",
    "| Feature Selection | Yes | No |\n",
    "| Closed Form | No | Yes |\n",
    "| Geometry | Diamond | Circle |\n",
    "\n",
    "---\n",
    "\n",
    "## 10. When to Use L2\n",
    "\n",
    "Use L2 when:\n",
    "\n",
    "- Many features are useful\n",
    "- You don't want feature selection\n",
    "- Features are correlated\n",
    "- You want stable, smooth shrinkage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ CELL 1: Import Libraries\n",
    "# =============================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"Libraries Imported Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bdd85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ CELL 2: Load Dataset\n",
    "# =============================\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "feature_names = diabetes.feature_names\n",
    "\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df[\"target\"] = y\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ CELL 3: Summary Statistics\n",
    "# =============================\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0215c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ CELL 4: Target Distribution\n",
    "# =============================\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df[\"target\"], bins=20)\n",
    "plt.title(\"Distribution of Target Variable\")\n",
    "plt.xlabel(\"Target Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7fb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ CELL 5: Correlation with Target\n",
    "# =============================\n",
    "\n",
    "correlation = df.corr()[\"target\"].sort_values(ascending=False)\n",
    "\n",
    "correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844dd2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ðŸ“Œ CELL 6: Train-Test Split\n",
    "# =============================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
